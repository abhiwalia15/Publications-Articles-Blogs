{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "relu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHBNm2APyx-a",
        "colab_type": "code",
        "outputId": "80db12c1-e30b-466c-f8cd-ba22c60f297b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99SNW-Dk0K6i",
        "colab_type": "code",
        "outputId": "76a96d7f-3161-4cef-f7b6-9451c9a7ed04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "X_train = np.array(df.iloc[:,1:])\n",
        "y_train = np.array(df.iloc[:,0])\n",
        "\n",
        "X_train = np.reshape(X_train,(-1,28,28,1))\n",
        "def create_dev_set(X_train, Y_train):\n",
        "    ## split 42000 into 35000 and 7000(0.16)\n",
        "    return train_test_split(X_train, Y_train, test_size = 0.166, random_state = 0)\n",
        "X_train, X_dev, y_train, y_dev = create_dev_set(X_train, y_train)\n",
        "print('Training data shape : ', X_train.shape, y_train.shape)\n",
        "print('Dev data shape : ', X_dev.shape, y_dev.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (35028, 28, 28, 1) (35028,)\n",
            "Dev data shape :  (6972, 28, 28, 1) (6972,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KftcZ6GBlJ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_dev = X_dev.astype('float32')\n",
        "X_train = X_train / 255.\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "y_train_one_hot = np.array(to_categorical(y_train))\n",
        "y_dev_one_hot = np.array(to_categorical(y_dev))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF5XR5cIabTq",
        "colab_type": "code",
        "outputId": "c189e99e-04d5-4c43-859a-d4fd8a9f66f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2e-9r1la-u",
        "colab_type": "code",
        "outputId": "6dfacf7c-1d08-4d2d-a01c-b9c351fadd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "num_classes = 10\n",
        "\n",
        "dr = Sequential()\n",
        "dr.add(Conv2D(32, kernel_size=(3,3),activation='linear',input_shape=(28,28,1),padding='same'))\n",
        "dr.add(BatchNormalization(axis=-1))\n",
        "dr.add(LeakyReLU(alpha=0.1))\n",
        "dr.add(MaxPooling2D((2,2),padding='same'))\n",
        "dr.add(Dropout(0.3))\n",
        "dr.add(Conv2D(64, (3,3), activation='linear',padding='same'))\n",
        "dr.add(BatchNormalization(axis=-1))\n",
        "dr.add(LeakyReLU(alpha=0.1))\n",
        "dr.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "dr.add(Dropout(0.3))\n",
        "dr.add(Conv2D(128, (3,3), activation='linear',padding='same'))\n",
        "dr.add(BatchNormalization(axis=-1))\n",
        "dr.add(LeakyReLU(alpha=0.1))                  \n",
        "dr.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "dr.add(Dropout(0.4))\n",
        "dr.add(Flatten())\n",
        "dr.add(Dense(120, activation='linear'))\n",
        "dr.add(BatchNormalization(axis=-1))\n",
        "dr.add(LeakyReLU(alpha=0.1))         \n",
        "dr.add(Dropout(0.3))         \n",
        "dr.add(Dense(40, activation='linear'))\n",
        "dr.add(BatchNormalization(axis=-1))\n",
        "dr.add(LeakyReLU(alpha=0.1))         \n",
        "dr.add(Dropout(0.2)) \n",
        "dr.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "dr.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "\n",
        "dr.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               245880    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 120)               480       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 40)                4840      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 40)                160       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                410       \n",
            "=================================================================\n",
            "Total params: 345,338\n",
            "Trainable params: 344,570\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjk-mqzApE3P",
        "colab_type": "code",
        "outputId": "758ed660-c4ea-48b0-a007-29fc88e7d098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "\n",
        "training = dr.fit(X_train, y_train_one_hot, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_dev, y_dev_one_hot))\n",
        "\n",
        "dr.save(\"Conv2D_DR_dropout.h5py\")\n",
        "\n",
        "test_eval = dr.evaluate(X_dev, y_dev_one_hot, verbose=0)\n",
        "print(test_eval)\n",
        "\n",
        "accuracy = training.history['acc']\n",
        "val_accuracy = training.history['val_acc']\n",
        "loss = training.history['loss']\n",
        "val_loss = training.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 35028 samples, validate on 6972 samples\n",
            "Epoch 1/30\n",
            "35028/35028 [==============================] - 119s 3ms/step - loss: 0.5536 - acc: 0.8464 - val_loss: 0.0802 - val_acc: 0.9763\n",
            "Epoch 2/30\n",
            "35028/35028 [==============================] - 118s 3ms/step - loss: 0.1665 - acc: 0.9533 - val_loss: 0.0568 - val_acc: 0.9822\n",
            "Epoch 3/30\n",
            "35028/35028 [==============================] - 117s 3ms/step - loss: 0.1317 - acc: 0.9625 - val_loss: 0.0430 - val_acc: 0.9862\n",
            "Epoch 4/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.1042 - acc: 0.9682 - val_loss: 0.0378 - val_acc: 0.9880\n",
            "Epoch 5/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0914 - acc: 0.9726 - val_loss: 0.0363 - val_acc: 0.9898\n",
            "Epoch 6/30\n",
            "35028/35028 [==============================] - 114s 3ms/step - loss: 0.0817 - acc: 0.9765 - val_loss: 0.0329 - val_acc: 0.9904\n",
            "Epoch 7/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0748 - acc: 0.9770 - val_loss: 0.0373 - val_acc: 0.9892\n",
            "Epoch 8/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0689 - acc: 0.9801 - val_loss: 0.0314 - val_acc: 0.9900\n",
            "Epoch 9/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0678 - acc: 0.9802 - val_loss: 0.0318 - val_acc: 0.9898\n",
            "Epoch 10/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0611 - acc: 0.9815 - val_loss: 0.0298 - val_acc: 0.9917\n",
            "Epoch 11/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0571 - acc: 0.9826 - val_loss: 0.0248 - val_acc: 0.9917\n",
            "Epoch 12/30\n",
            "35028/35028 [==============================] - 114s 3ms/step - loss: 0.0544 - acc: 0.9837 - val_loss: 0.0272 - val_acc: 0.9921\n",
            "Epoch 13/30\n",
            "35028/35028 [==============================] - 115s 3ms/step - loss: 0.0551 - acc: 0.9841 - val_loss: 0.0296 - val_acc: 0.9915\n",
            "Epoch 14/30\n",
            "35028/35028 [==============================] - 114s 3ms/step - loss: 0.0507 - acc: 0.9850 - val_loss: 0.0256 - val_acc: 0.9917\n",
            "Epoch 15/30\n",
            "35028/35028 [==============================] - 114s 3ms/step - loss: 0.0463 - acc: 0.9862 - val_loss: 0.0291 - val_acc: 0.9918\n",
            "Epoch 16/30\n",
            "23232/35028 [==================>...........] - ETA: 35s - loss: 0.0493 - acc: 0.9852"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDZaZHD204ut",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPAF0cEKlzbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training dataset evaluation\")\n",
        "test_eval = dr.evaluate(X_train, y_train_one_hot, verbose=0)\n",
        "print(test_eval)\n",
        "\n",
        "print(\"Dev dataset evaluation\")\n",
        "test_eval = dr.evaluate(X_dev, y_dev_one_hot, verbose=0)\n",
        "print(test_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dkpU6xtsgZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}